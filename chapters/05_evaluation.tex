\chapter{Evaluation}\label{chapter:evaluation}

This section will evaluate our proposed concurrent range lock under different scenarios. 
The goal is to see the scalability and throughput of our mechanism compared to state-of-the-art range locks.

\section{Variants}

We denote our primary implementation as \texttt{Our}. 
In addition to \texttt{Our}, we implement two different variants for comparison. 
The first variant is a scalable range lock proposed by Kogan et al.~\parencite{kogan2020scalable}, denoted as \texttt{Scalable RL}. 
We specifically implemented the Exclusive Access Variant presented in their paper, as it aligns with the focus of our research. 
The second variant is a skip list range lock proposed by Song et al.~\parencite{song2013parallelizing}, which we denote as \texttt{Song RL}.

\section{Benchmark enviroment}

For benchmark purposes, we utilized a server with an AMD Ryzen 9 7950X processor, which features 16 cores and 32 threads, providing substantial computational power for the experiments. 
The server configuration included a virtual memory cache with a capacity of 128 GB, backed by 32 GB of physical memory. 
The cache management aimed to minimize eviction sizes to enhance performance and reliability during the benchmarks.

\section{Microbenchmark}\label{sec:microbenchmark}

\subsection{Workload}\label{subsec:workload}
The primary objective of a concurrent range lock mechanism is to enable multiple threads to access disjoint parts of the same shared object efficiently. 
To simulate and evaluate the effectiveness of different range locking strategies, we utilize the \texttt{mmap()} system call to create a shared object in memory and the \texttt{memset()} function to simulate write operations to this shared object. 
For each range, we will write 1KB. 
The use of \texttt{memset()} serves as a placeholder for actual modifications, enabling us to focus on the performance characteristics of the locking mechanism itself.

To explore various levels of contention and potential usage scenarios for range locks, we have devised two distinct workloads, each designed to stress the locking mechanism under different conditions:

\begin{itemize} 
    \item \textbf{\texttt{W1}:} In this workload, each thread operates with fine granularity. 
    A thread locks a single memory range, performs a modification (simulated by \texttt{memset()}), and immediately releases the lock before proceeding to the next range in its queue. 
    This approach simulates a scenario with minimal contention, focusing on the efficiency of the lock mechanism in handling rapid lock acquisition and release cycles. 
    The primary objective is to assess the overhead introduced by the locking mechanism under low contention and to evaluate its performance in scenarios demanding high throughput with minimal waiting times.
    
    \item \textbf{\texttt{W2}:} This workload introduces a more complex and realistic scenario. 
    Here, threads perform batched memory operations, where a series of memory ranges (typically 16) are locked, modified (simulated by \texttt{memset()}) and then unlocked in a single batch. 
    The goal is to test all variants under heavier threaded conditions. 
    By locking and unlocking in batches, the number of ranges within the data structure increases, providing insight into how efficiently each variant can search, lock, and unlock ranges as the load increases. 
    This workload emphasizes the performance of the locking mechanism in handling more substantial, real-world use cases where contention may be higher.
\end{itemize}

Through these workloads, we aim to comprehensively evaluate the performance of the concurrent range lock mechanism under different workloads and contention scenarios. 
Each workload provides insights into the lock's scalability, efficiency, and overall robustness in handling varying degrees of parallelism and contention.

\subsection{Optimal Height for Range Locking}

The skip list height in our range-locking mechanism plays a critical role in balancing performance and resource utilization. 
A skip list with insufficient height may need to optimize lookup times effectively, leading to slower performance. 
In contrast, an excessive height increases memory consumption and management overhead without proportionate gains in efficiency. 
This test aims to determine the optimal height for our concurrent range-locking mechanism before comparing it to alternative approaches. 
We conducted experiments using the two workloads described in \ref{subsec:workload} to identify the best skip list height.

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            xlabel={Height},
            ylabel={Runtime (seconds)},
            ytick={4e-2, 5e-2, 6e-2, 7e-2, 8e-2},
            yticklabels={$4 \cdot 10^{-2}$, $5 \cdot 10^{-2}$, $6 \cdot 10^{-2}$, $7 \cdot 10^{-2}$, $8 \cdot 10^{-2}$},
            scaled y ticks=false,
            title={Runtime on different heights},
            grid=major,
            width=0.8\textwidth,
            height=0.6\textwidth,
            enlargelimits=false,
            ymax=0.08,
            mark options={solid},
            enlarge x limits={abs=0.75cm},
            enlarge y limits=false,
            legend style={at={(0.5,-0.25)},anchor=north,legend columns=-1},
        ]
        \addplot[color=black,line width=0.7pt]
        table[x=Height,y=Runtime,col sep=comma] {data/height2.csv};
        \addplot[color=red,line width=0.7pt]
        table[x=Height,y=Runtime,col sep=comma] {data/height1.csv};
        \legend{W1, W2}

        \draw[dashed, thick] (axis cs:10,0) -- (axis cs:10,0.1);

        \end{axis}
    \end{tikzpicture}
    \caption{Runtime for different heights of range lock}
\end{figure}

For \textbf{W1}, where contention is minimal, and each thread locks and releases ranges immediately, the height of the skip list has negligible impact on performance. 
In this scenario, since the number of ranges locked at any given time is limited to the number of active worker threads, the benefits of a taller skip list are not realized. 
The overhead of managing additional levels outweighs any potential gains, leading to similar performance across different heights.

For \textbf{W2}, the total runtime decreases as the skip list height increases, aligning with the expected behavior. 
The multi-level structure of skip lists allows for faster lookups, reducing runtime as height increases. 
However, beyond a height of 10, further increases yield diminishing returns. 
This is due to the probabilistic level assignment in skip lists, where the chance of a node reaching higher levels decreases exponentially (e.g., level 12 has a probability of about \(\frac{1}{2^{12}} \approx 0.00024\%\)). 
The sparsely populated upper levels contribute little to performance improvement but increase memory usage.

Based on these observations, we identify a sweet spot at a height of \texttt{10}, where the trade-off between performance and resource utilization is optimized. 
This height balances the need for efficient lookups with manageable memory overhead, making it the ideal choice for our range-locking mechanism in subsequent benchmarks.

\subsection{Result}

Figure \ref{fig:workload1} shows the number of successful locks and unlocks per second with increasing working threads under \textbf{W1}. We can see that \texttt{Our} variant has good scalability and outperforms the other two. We archive four times more operations than \texttt{Scalable RL} and twelve times more than \texttt{Song RL}. The poor performance of \texttt{Song RL} is due to the immediate locking and releasing mechanism, combined with the low memory overhead of \texttt{memset} (1KB per range). The spinlock in \texttt{Song RL} becomes a significant point of contention, leading to its poor performance. Additionally, since the locks are released immediately, \texttt{Song RL} cannot effectively leverage its skip list data structure, as the maximum number of ranges in the list is limited to the number of worker threads. However, in more realistic scenarios, such as those discussed in \ref{sec:leanstore} or \textbf{W2}, we will see \texttt{Song RL} perform much better.

Figure \ref{fig:workload2} illustrates the same result for \textbf{W2}, \texttt{Our} variant continued to outperform the others, achieving two to nine times more operations than \texttt{Scalable RL} and two to six times more than \texttt{Song RL}. 
In this workload, the number of ranges locked simultaneously increases to the number of threads multiplied by the batch size (16). 
This allowed \texttt{Song RL} to perform significantly better compared to \texttt{Scalable RL}. 
However, \texttt{Scalable RL} demonstrated better scalability as the number of worker threads increased. Beyond sixteen threads, \texttt{Scalable RL} began to surpass \texttt{Song RL} in performance.

In summary, \texttt{Our} variant consistently outperforms both \texttt{Scalable RL} and \texttt{Song RL} across different workloads. 
While \texttt{Song RL} struggles with contention in \textbf{W1}, it performs better in more complex scenarios like \textbf{W2}. 
However, \texttt{Scalable RL} demonstrates better scalability with increasing thread counts, eventually surpassing \texttt{Song RL} as threads increase.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\textwidth,
            height=0.45\textwidth,
            ytick={0.5e7, 1e7, 1.5e7},
            yticklabels={$0.5 \cdot 10^{7}$, $1 \cdot 10^{7}$, $1.5 \cdot 10^{7}$},
            scaled y ticks=false,
            symbolic x coords={4,8,12,16,20,24,28,32},
            xtick=data,
            grid=minor,
            ylabel={Total number of locks and unlocks per second},
            xlabel={Total number of worker threads},
            ymax=18000000,
            ymin=-1,
            mark options={solid},
            nodes near coords,
            every node near coord/.append style={font=\tiny},
            enlarge x limits={abs=0.75cm},
            enlarge y limits=false,
            legend style={at={(0.5,-0.25)}, anchor=north,legend columns=-1},
            ]
            \addplot[color=red,line width=0.7pt] table [x=NumThreads, y expr=1000000/\thisrow{Duration}, col sep=comma] {data/data_v0.csv};
            \addplot[color=black,line width=0.7pt] table [x=NumThreads, y expr=1000000/\thisrow{Duration}, col sep=comma] {data/data_v2.csv};
            \addplot[color=orange,line width=0.7pt] table [x=NumThreads, y expr=1000000/\thisrow{Duration}, col sep=comma] {data/data_v3.csv};
            \legend{Our, Scalable RL, Song RL}
        \end{axis}
    \end{tikzpicture}
    \caption{Microbenchmark for workload \textbf{W1}}
    \label{fig:workload1}
\end{figure}

\begin{figure}[H]
    \begin{tikzpicture}
        \centering
        \begin{axis}[
            width=\textwidth,
            height=0.45\textwidth,
            symbolic x coords={4,8,12,16,20,24,28,32},
            xtick=data,
            grid=minor,
            ytick={0.2e6, 0.4e6, 0.6e6, 0.8e6, 1e6, 1.2e6},
            yticklabels={$0.2 \cdot 10^{6}$, $0.4 \cdot 10^{6}$, $0.6 \cdot 10^{6}$, $0.8 \cdot 10^{6}$, $1.0 \cdot 10^{6}$, $1.2 \cdot 10^{6}$},
            scaled y ticks=false,
            ylabel={Total number of locks and unlock per second},
            xlabel={Total number of worker threads},
            ymax=1300000,
            ymin=-1,
            mark options={solid},
            nodes near coords,
            every node near coord/.append style={font=\tiny},
            enlarge x limits={abs=0.75cm},
            enlarge y limits=false,
            legend style={at={(0.5,-0.25)}, anchor=north,legend columns=-1},
            ]
            \addplot[color=red,line width=0.7pt] table [x=NumThreads, y expr=200000/\thisrow{Duration}, col sep=comma] {data/w2_v0.csv};
            \addplot[color=black,line width=0.7pt] table [x=NumThreads, y expr=200000/\thisrow{Duration}, col sep=comma] {data/w2_v2.csv};
            \addplot[color=orange,line width=0.7pt] table [x=NumThreads, y expr=200000/\thisrow{Duration}, col sep=comma] {data/w2_v3.csv};
            \legend{Our, Scalable RL, Song RL}
        \end{axis}
    \end{tikzpicture}
    \caption{Microbenchmark for workload \textbf{W2}}
    \label{fig:workload2}
\end{figure}

\newpage

\section{Leanstore integration}\label{sec:leanstore}

While microbenchmarks are useful for evaluating and comparing range locks at algorithm level, they often do not capture the complexities of real-world workloads. 
Testing in real system allows us to move beyond synthetic benchmarks and evaluate the effectiveness of range locks in a live, operational environment where factors like transaction throughput, latency, and contention can significantly impact performance. 
This ensures that the range locks are not only theoretically efficient but also practically robust under realistic conditions. For those reason, we run an other benchmark of range lock integrated into \texttt{Leanstore}.

\subsection{Leanstore}

\texttt{Leanstore}~\parencite{leis2018leanstore} is a high-performance storage engine designed to support various database management systems. 
To further enhance its capabilities, Nguyen et al.~\parencite{nguyen2024files} introduced a comprehensive design for allocating and logging large objects, which has been integrated into Leanstore. 
Their performance study demonstrates that this approach not only outperforms many popular file systems but also ensures transactional consistency and durability for large objects. Given the crucial role that range locks play in their design, we integrated our concurrent range lock mechanism to enable realistic and rigorous benchmarking.

In the proposed design, range locks synchronize access to shared aliasing areas, which are contiguous ranges of virtual memory addresses used to present disjointed extents as contiguous memory. 
When a worker needs to allocate virtual memory for large BLOBs, particularly when these BLOBs exceed the size of the worker-local aliasing area, it must reserve free virtual memory from the shared aliasing area. 
A range lock mechanism prevents concurrent workers from accessing overlapping memory regions. 
The range lock operates by locking specific ranges within the shared aliasing area, ensuring that only one worker can modify or access a particular memory range. 
This prevents race conditions and ensures data consistency while simultaneously allowing multiple workers to operate on different memory ranges. 

\subsection{Variants}

We integrated all three versions as described in section \ref{sec:microbenchmark}. 
Additionally, we included the original, specifically optimized range lock version by the author as a fourth variant. 
This range lock employs a bitmap and \texttt{compare-and-swap}, making it lightweight and efficient, especially for managing small to moderate numbers of logical blocks in memory.

\subsection{Workload}

The experiment, utilizing synthetic YCSB~\parencite{cooper2010benchmarking} workloads, was designed to evaluate the performance of LeanStore under a read-intensive, multithreaded environment. 
The workload comprises exclusively read operations, executed over a 10-second duration, with each read operation employing a straightforward \texttt{memcpy()} function. Each record in the workload has a payload size of 1 MB, with 1000 records being processed. 
The experiment also incorporates a buffer management configuration that allocates 128 GB of virtual and 32 GB of physical memory, providing a robust test of LeanStore's ability to manage large data sets under constrained physical memory conditions.

\subsection{Result}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=\textwidth,
            height=0.7\textwidth,
            title={Comparison of txn by increasing amount of thread worker},
            title style={at={(0.5,1.1)}},
            xlabel={Amount of worker thread},
            ylabel={txn/s},
            ytick={1e4, 2e4, 3e4, 4e4, 5e4, 6e4, 7e4},
            yticklabels={$1 \cdot 10^{4}$, $2 \cdot 10^{4}$, $3 \cdot 10^{4}$, $4 \cdot 10^{4}$, $5 \cdot 10^{4}$, $6 \cdot 10^{4}$, $7 \cdot 10^{4}$},
            scaled y ticks=false,
            mark options={solid},
            legend style={at={(0.5,-0.25)}, anchor=north, legend columns=4},
            ymajorgrids=true,
            legend cell align={left},
            ]
            \addplot[color=blue,mark=none,line width=0.7pt] 
            table[x=worker_count, y expr=\thisrow{txn}/10, col sep=comma] {data/var_0.csv};
            \addlegendentry{Bitmap}
                
            \addplot[color=red,mark=none,line width=0.7pt]
            table[x=worker_count, y expr=\thisrow{txn}/10, col sep=comma] {data/var_1.csv};
            \addlegendentry{Our}
                
            \addplot[color=black,mark=none,line width=0.7pt] 
            table[x=worker_count, y expr=\thisrow{txn}/10, col sep=comma] {data/var_2.csv};
            \addlegendentry{Scalable RL}
            
            \addplot[color=orange,mark=none,line width=0.7pt] 
            table[x=worker_count, y expr=\thisrow{txn}/10, col sep=comma] {data/var_3.csv};
            \addlegendentry{Song RL}
        \end{axis}
    \end{tikzpicture}
    \caption{Comparison of transactions by increasing the number of thread workers.}
    \label{fig:txn_comparison}
\end{figure}

We evaluated the throughput of four distinct variants as the number of worker threads increased, as depicted in Figure \ref{fig:txn_comparison}. 
As anticipated, the \texttt{Bitmap} implementation consistently outperformed the other three variants. 
This superiority can be attributed mainly to its optimized use of the aliasing arena, making it the most efficient workload handling. 
Our implementation (\texttt{Our}) demonstrated competitive performance, closely trailing \texttt{Bitmap} in terms of transactions per second. 
Both \texttt{Bitmap} and \texttt{Our} showed effective scalability with an increasing number of worker threads, though \texttt{Bitmap} maintained a consistent, albeit slight, performance advantage.

Conversely, \texttt{Song RL} initially exhibited substantial throughput but encountered a sharp decline beyond 24 worker threads. 
This decline underscores the limitations of its coarse-grained range lock mechanism, as discussed in \ref{subsec:listbase}. 
The single spinlock in \texttt{Song RL} becomes a significant bottleneck in high-contention scenarios, leading to marked performance degradation. 
On the other hand, the \texttt{Scalable RL} variant showed steady, linear throughput growth. 
However, its overall performance remained considerably lower than the other variants, highlighting its limitations.

An additional key observation is the difficulty faced by the \texttt{Bitmap}, \texttt{Our}, and \texttt{Song RL} variants in scaling effectively beyond 16 worker threads. 
This limitation is due mainly to the BLOB size in our workload. With a BLOB size of 1MB and 16 worker threads, the combined size of the client-side buffer and the internal DBMS memory block for the BLOB exceeds the L3 cache capacity (32MB in our machine), resulting in significant contention at the L3 cache. 
Furthermore, LeanStore's use of \texttt{memcpy} for read operations exacerbates this issue. \texttt{memcpy} consumes 2MB of memory read and write for every 1MB BLOB. 
An average throughput of approximately 60,000 operations per second equals over 110 GB of memory consumed by \texttt{memcpy}, which saturates the memory bandwidth and hinders the application's ability to scale.

We also analyzed other performance metrics, such as cycles, instructions, and L1 cache misses. 
As illustrated in Figure \ref{fig:comparison_metrics}, both the \texttt{Bitmap} and \texttt{Our} implementations maintained stable levels of cycles, instructions, and L1 cache misses as the number of threads increased. 
In contrast, \texttt{Song RL} exhibited a significant rise in the number of instructions with additional threads, indicating inefficiencies under higher loads. 
Meanwhile, \texttt{Scalable RL} demonstrated better scalability, with a decreasing number of L1 misses and instructions as the workload intensified.


\begin{figure}[h]
    \centering

    % First graph: cycle/s
    \subfloat[Cycles by thread workers]{%
        \begin{tikzpicture}
            \begin{axis}[
 width=0.8\textwidth,
 height=0.35\textwidth,
 ylabel={Cycles},
 legend style={at={(1,1)}, anchor=north east, legend columns=2, font=\tiny},
 ymajorgrids=true,
 grid style=dashed,
 legend cell align={left},
 ]
    
            \addplot[color=blue,mark=none,line width=1pt] 
 table[x=worker_count, y=cycle, col sep=comma] {data/var_0.csv};
            \addlegendentry{Bitmap}
    
            \addplot[color=red,mark=none,line width=1pt] 
 table[x=worker_count, y=cycle, col sep=comma] {data/var_1.csv};
            \addlegendentry{Our}
    
            \addplot[color=black,mark=none,line width=1pt] 
 table[x=worker_count, y=cycle, col sep=comma] {data/var_2.csv};
            \addlegendentry{Scalable RL}
    
            \addplot[color=orange,mark=none,line width=1pt] 
 table[x=worker_count, y=cycle, col sep=comma] {data/var_3.csv};
            \addlegendentry{Song RL}
    
            \end{axis}
        \end{tikzpicture}
 }

    % Second graph: instr
    \subfloat[Instructions by thread workers]{%
        \begin{tikzpicture}
            \begin{axis}[
 width=0.8\textwidth,
 height=0.35\textwidth,
 ylabel={Instrs},
 legend style={at={(1,1)}, anchor=north east, legend columns=2, font=\tiny},
 ymajorgrids=true,
 grid style=dashed,
 legend cell align={left},
 ]
    
            \addplot[color=blue,mark=none,line width=1pt] 
 table[x=worker_count, y=instr, col sep=comma] {data/var_0.csv};
            \addlegendentry{Bitmap}
    
            \addplot[color=red,mark=none,line width=1pt] 
 table[x=worker_count, y=instr, col sep=comma] {data/var_1.csv};
            \addlegendentry{Our}
    
            \addplot[color=black,mark=none,line width=1pt] 
 table[x=worker_count, y=instr, col sep=comma] {data/var_2.csv};
            \addlegendentry{Scalable RL}
    
            \addplot[color=orange,mark=none,line width=1pt] 
 table[x=worker_count, y=instr, col sep=comma] {data/var_3.csv};
            \addlegendentry{Song RL}
    
            \end{axis}
        \end{tikzpicture}%
 }

    % Third graph: L1-miss
    \subfloat[L1-misses by thread workers]{%
        \begin{tikzpicture}
            \begin{axis}[
 width=0.8\textwidth,
 height=0.35\textwidth,
 ylabel={L1-misses},
 legend style={at={(1,1)}, anchor=north east, legend columns=2, font=\tiny},
 ymajorgrids=true,
 grid style=dashed,
 legend cell align={left},
 ]
    
            \addplot[color=blue,mark=none,line width=1pt] 
 table[x=worker_count, y=L1-miss, col sep=comma] {data/var_0.csv};
            \addlegendentry{Bitmap}
    
            \addplot[color=red,mark=none,line width=1pt] 
 table[x=worker_count, y=L1-miss, col sep=comma] {data/var_1.csv};
            \addlegendentry{Our}
    
            \addplot[color=black,mark=none,line width=1pt] 
 table[x=worker_count, y=L1-miss, col sep=comma] {data/var_2.csv};
            \addlegendentry{Scalable RL}
    
            \addplot[color=orange,mark=none,line width=1pt] 
 table[x=worker_count, y=L1-miss, col sep=comma] {data/var_3.csv};
            \addlegendentry{Song RL}
    
            \end{axis}
        \end{tikzpicture}%
 }

    \caption{Comparison of cycles, instructions, and L1-misses by increasing the number of thread workers.}
    \label{fig:comparison_metrics}
\end{figure}

