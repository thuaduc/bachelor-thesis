\chapter{Evaluation}\label{chapter:evaluation}

This section will evaluate our proposed concurrent range lock under different scenarios. 
The goal is to see the scalability and throughput of our mechanism compared to state-of-the-art range locks.

\section{Competitors}

We denote our primary implementation as \texttt{Our}. 
In addition to \texttt{Our}, we implement two different competitors for comparison. 
The first competitor is a scalable range lock proposed by Kogan et al.~\parencite{kogan2020scalable}, denoted as \texttt{Scalable RL}. 
We specifically implemented the Exclusive Access variant presented in their paper, as it aligns with the focus of our research. 
The second competitor is a skip list range lock proposed by Song et al.~\parencite{song2013parallelizing}, which we denote as \texttt{Song RL}.

\section{Benchmark enviroment}

For benchmark purposes, we utilized a server with an AMD Ryzen 9 7950X processor, which features 16 cores and 32 threads, providing computational power for the experiments. 
The server configuration included a virtual memory cache with a capacity of 128 GB, backed by 32 GB of physical memory. 

\section{Microbenchmark}\label{sec:microbenchmark}

\subsection{Workload}\label{subsec:workload}
The primary objective of a concurrent range lock mechanism is to enable multiple threads to access disjoint parts of the same shared object efficiently. 
To simulate and evaluate the effectiveness of different range locking strategies, we utilize the \texttt{mmap()} system call to create a shared object in memory and the \texttt{memset()} function to simulate write operations to this shared object. 
For each range, we will write 1KB. 
The use of \texttt{memset()} serves as a placeholder for actual modifications, enabling us to focus on the performance characteristics of the locking mechanism itself.

To explore various levels of contention and potential usage scenarios for range locks, we have devised two distinct workloads, each designed to stress the locking mechanism under different conditions:

\begin{itemize} 
    \item \textbf{\texttt{W1}:} In this workload, each thread operates with fine granularity. 
    A thread locks a single memory range, performs a modification (simulated by \texttt{memset()}), and immediately releases the lock before proceeding to the next range in its queue. 
    This approach simulates a scenario with minimal contention, focusing on the efficiency of the lock mechanism in handling rapid lock acquisition and release cycles. 
    The primary objective is to assess the overhead introduced by the locking mechanism under low contention and to evaluate its performance in scenarios demanding high throughput with minimal waiting times.
    
    \item \textbf{\texttt{W2}:} This workload introduces a more complex and realistic scenario. 
    Here, threads perform batched memory operations, where a series of memory ranges (typically 16) are locked, modified (simulated by \texttt{memset()}) and then unlocked in a single batch. 
    The goal is to test all competitors under heavier threaded conditions. 
    By locking and unlocking in batches, the number of ranges within the data structure increases, providing insight into how efficiently each competitor can search, lock, and unlock ranges as the load increases. 
    This workload emphasizes the performance of the locking mechanism in handling real-world use cases where contention may be higher.
\end{itemize}

Through these workloads, we aim to comprehensively evaluate the performance of the concurrent range lock mechanism under different workloads and contention scenarios. 
Each workload provides insights into the lock's scalability, efficiency, and overall robustness in handling varying degrees of parallelism and contention.

\subsection{Optimal Height for Range Locking}

The skip list height in our range-locking mechanism plays a critical role in balancing performance and resource utilization. 
A skip list with insufficient height may need to optimize lookup times effectively, leading to slower performance. 
In contrast, an excessive height increases memory consumption and management overhead without proportionate gains in efficiency. 
This test aims to determine the optimal height for our concurrent range-locking mechanism before comparing it to alternative approaches. 
We conducted experiments using the two workloads described in Subsection \ref{subsec:workload} to identify the best skip list height.

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            xlabel={Height},
            ylabel={Runtime (milliseconds)},
            ytick={40, 50, 60, 70, 80},
            yticklabels={$40$, $50$, $60$, $70$, $80$},
            xtick style={thick, black},
            ytick style={thick, black},
            tick align=center,
            scaled y ticks=false,
            title={Runtime on different heights},
            grid=major,
            grid style=dashed,
            width=0.8\textwidth,
            height=0.6\textwidth,
            enlargelimits=false,
            ymax=80,
            mark options={solid},
            enlarge x limits={abs=0.75cm},
            enlarge y limits=false,
            legend style={at={(0.5,-0.25)},anchor=north,legend columns=-1},
        ]
        \addplot[color=black,line width=0.7pt]
        table[x=Height,y expr=\thisrow{Runtime}*1000,col sep=comma] {data/height2.csv};
        \addplot[color=red,line width=0.7pt]
        table[x=Height,y expr=\thisrow{Runtime}*1000,col sep=comma] {data/height1.csv};
        \legend{W1, W2}

        \draw[dashed, thick] (axis cs:10,0) -- (axis cs:10,100);

        \end{axis}
    \end{tikzpicture}
    \caption{Runtime for different heights of range lock}
\end{figure}


For \textbf{W1}, where contention is minimal, and each thread locks and releases ranges immediately, the height of the skip list has negligible impact on performance. 
In this scenario, since the number of ranges locked at any given time is limited to the number of active worker threads, the benefits of a taller skip list are not realized. 
The overhead of managing additional levels outweighs any potential gains, leading to similar performance across different heights.

For \textbf{W2}, the total runtime decreases as the skip list height increases, aligning with the expected behavior. 
The multi-level structure of skip lists allows for faster lookups, reducing runtime as height increases. 
However, beyond a height of 10, further increases yield diminishing returns. 
This is due to the probabilistic level assignment in skip lists, where the chance of a node reaching higher levels decreases exponentially (e.g., level 12 has a probability of about \(\frac{1}{2^{12}} \approx 0.00024\%\)). 
The sparsely populated upper levels contribute little to performance improvement but increase memory usage.

Based on these observations, we identify a sweet spot at a height of \texttt{10}, where the trade-off between performance and resource utilization is optimized. 
This height balances the need for efficient lookups with manageable memory overhead, making it the ideal choice for our range-locking mechanism in subsequent benchmarks.

\subsection{Result}

Figure \ref{fig:workload1} shows the number of successful locks and unlocks per second with increasing working threads under \textbf{W1}. We can see that \texttt{Our} has good scalability and outperforms the other two. We archive four times more operations than \texttt{Scalable RL} and twelve times more than \texttt{Song RL}. The poor performance of \texttt{Song RL} is due to the immediate locking and releasing mechanism, combined with the low memory overhead of \texttt{memset} (1KB per range). The spinlock in \texttt{Song RL} becomes a significant point of contention, leading to its poor performance. Additionally, since the locks are released immediately, \texttt{Song RL} cannot effectively leverage its skip list data structure, as the maximum number of ranges in the list is limited to the number of worker threads. However, in more realistic scenarios, such as those discussed in Section \ref{sec:leanstore} or \textbf{W2}, we will see \texttt{Song RL} perform much better.

Figure \ref{fig:workload2} illustrates the same result for \textbf{W2}, \texttt{Our} continued to outperform the others, achieving two to nine times more operations than \texttt{Scalable RL} and two to six times more than \texttt{Song RL}. 
In this workload, the number of ranges locked simultaneously increases to the number of threads multiplied by the batch size (16). 
This allowed \texttt{Song RL} to perform significantly better compared to \texttt{Scalable RL}. 
However, \texttt{Scalable RL} demonstrated better scalability as the number of worker threads increased. Beyond sixteen threads, \texttt{Scalable RL} began to surpass \texttt{Song RL} in performance.

In summary, \texttt{Our} consistently outperforms both \texttt{Scalable RL} and \texttt{Song RL} across different workloads. 
While \texttt{Song RL} struggles with contention in \textbf{W1}, it performs better in more complex scenarios like \textbf{W2}. 
However, \texttt{Scalable RL} demonstrates better scalability with increasing thread counts, eventually surpassing \texttt{Song RL} as threads increase.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=0.8\textwidth,
            height=0.4\textwidth,
            grid=major,
            grid style=dashed,
            xmin=0,
            ymin=0,
            ymax=18,
            xtick=data,
            xtick style={thick, black},
            ytick style={thick, black},
            tick align=center,
            ytick={0, 5, 10, 15},
            yticklabels={$0$, $5M$, $10M$, $15M$},
            scaled y ticks=false,
            symbolic x coords={0,4,8,12,16,20,24,28,32},
            ylabel={Number of locks and unlocks per second (M)},
            xlabel={Number of worker threads},
            mark options={solid},
            legend style={at={(0.5,-0.3)}, anchor=north,legend columns=-1},
            ]
            \addplot[color=red,line width=0.7pt] table [x=NumThreads, y expr=(1000000/\thisrow{Duration})/1e6, col sep=comma] {data/data_v0.csv};
            \addplot[color=black,line width=0.7pt] table [x=NumThreads, y expr=(1000000/\thisrow{Duration})/1e6, col sep=comma] {data/data_v2.csv};
            \addplot[color=orange,line width=0.7pt] table [x=NumThreads, y expr=(1000000/\thisrow{Duration})/1e6, col sep=comma] {data/data_v3.csv};
            \legend{Our, Scalable RL, Song RL}
        \end{axis}
    \end{tikzpicture}
    \caption{\textbf{Workload 1}: Lock and unlock operations per second. \texttt{Our} achieves 4x more operations than \texttt{Scalable RL} and 12x more than \texttt{Song RL}.}
    \label{fig:workload1}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=0.8\textwidth,
            height=0.4\textwidth,
            grid=major,
            grid style=dashed,
            xmin=0,
            ymin=0,
            ymax=1.3,
            xtick=data,
            xtick style={thick, black},
            ytick style={thick, black},
            tick align=center,
            ytick={0, 0.2, 0.4, 0.6, 0.8, 1, 1.2},
            yticklabels={$0$, $0.2M$, $0.4M$, $0.6M$, $0.8M$, $1M$, $1.2M$},
            scaled y ticks=false,
            symbolic x coords={0,4,8,12,16,20,24,28,32},
            ylabel={Number of locks and unlock per second (M)},
            xlabel={Number of worker threads},
            mark options={solid},
            legend style={at={(0.5,-0.3)}, anchor=north,legend columns=-1},
            ]
            \addplot[color=red,line width=0.7pt] table [x=NumThreads, y expr=200000/\thisrow{Duration}/1e6, col sep=comma] {data/w2_v0.csv};
            \addplot[color=black,line width=0.7pt] table [x=NumThreads, y expr=200000/\thisrow{Duration}/1e6, col sep=comma] {data/w2_v2.csv};
            \addplot[color=orange,line width=0.7pt] table [x=NumThreads, y expr=200000/\thisrow{Duration}/1e6, col sep=comma] {data/w2_v3.csv};
            \legend{Our, Scalable RL, Song RL}
        \end{axis}
    \end{tikzpicture}
    \caption{\textbf{Workload 2}: Lock and unlock operations per second. \texttt{Our} achieves 2-9x more than \texttt{Scalable RL} and 2-6x more than \texttt{Song RL}.}
    \label{fig:workload2}
\end{figure}

\newpage

\section{Evaluation with real use-cases}\label{sec:leanstore}

While microbenchmarks are useful for evaluating and comparing range locks at algorithm level, they often do not capture the complexities of real-world workloads. 
Testing in real system allows us to move beyond synthetic benchmarks and evaluate the effectiveness of range locks in a live, operational environment where factors like transaction throughput, latency, and contention can significantly impact performance. 
This ensures that the range locks are not only theoretically efficient but also practically robust under realistic conditions. For those reason, we run an other benchmark of range lock integrated into \texttt{Leanstore}.

\subsection{Leanstore}

\texttt{Leanstore}~\parencite{leis2018leanstore} is a high-performance storage engine designed to support various database management systems. 
To further enhance its capabilities, Nguyen et al.~\parencite{nguyen2024files} introduced a comprehensive design for allocating and logging large objects, which has been integrated into Leanstore. 
Their performance study demonstrates that this approach not only outperforms many popular file systems but also ensures transactional consistency and durability for large objects. Given the crucial role that range locks play in their design, we integrated our concurrent range lock mechanism to enable realistic and rigorous benchmarking.

In the proposed design, range locks synchronize access to shared aliasing areas, which are contiguous ranges of virtual memory addresses used to present disjointed extents as contiguous memory. 
When a worker needs to allocate virtual memory for large BLOBs, particularly when these BLOBs exceed the size of the worker-local aliasing area, it must reserve free virtual memory from the shared aliasing area. 
A range lock mechanism prevents concurrent workers from accessing overlapping memory regions. 
The range lock operates by locking specific ranges within the shared aliasing area, ensuring that only one worker can modify or access a particular memory range. 
This prevents race conditions and ensures data consistency while simultaneously allowing multiple workers to operate on different memory ranges. 

\subsection{Competitors}

We integrated all three versions described in Section \ref{sec:microbenchmark}. 
Additionally, we included the original, specifically optimized range lock version by the author as a fourth competitor. 
We denoted it as \texttt{Bitmap}

\texttt{Bitmap} manages locking over a range of blocks in a buffer. It iterates through the specified block range in chunks, calculating which bits in the lock need to be updated for each chunk. It tries to set the corresponding bits case lock and clear bits case unlock in an atomic manner. If a bit was already set by another thread, the function detects this conflict, aborts the current operation, and undoes any changes made so far. 

\texttt{Bitmap} is lightweight and efficient implementation of range locking.
However, it does not support locking and unlocking a specific range from page x to page y, but rather an entire block of 1GB. 
Since our research focuses exclusively on the generalized use case of range locking, we have chosen not to consider this approach as a competitor in our project.

\subsection{Workload}

The experiment, utilizing synthetic YCSB~\parencite{cooper2010benchmarking} workloads, was designed to evaluate the performance of LeanStore under a read-intensive, multithreaded environment. 
The workload comprises exclusively read operations, executed over a 10-second duration, with each read operation employing a straightforward \texttt{memcpy()} function. Each record in the workload has a payload size of 1 MB, with 1000 records being processed. 
The experiment also incorporates a buffer management configuration that allocates 128 GB of virtual and 32 GB of physical memory, providing a robust test of LeanStore's ability to manage large data sets under constrained physical memory conditions.

\subsection{Result}

\subsubsection*{Throughput}

\begin{figure}[h!]
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            width=0.8\textwidth,
            height=0.6\textwidth,
            title style={at={(0.5,1.1)}},
            xmin=0,
            ymin=0,
            xtick style={thick, black},
            ytick style={thick, black},
            tick align=center,
            xlabel={Amount of worker thread},
            ylabel={txn/s},
            ytick={0, 1e4, 2e4, 3e4, 4e4, 5e4, 6e4, 7e4},
            yticklabels={$0$, $1 \cdot 10^{4}$, $2 \cdot 10^{4}$, $3 \cdot 10^{4}$, $4 \cdot 10^{4}$, $5 \cdot 10^{4}$, $6 \cdot 10^{4}$, $7 \cdot 10^{4}$},
            scaled y ticks=false,
            grid=major,
            grid style=dashed,
            mark options={solid},
            legend style={at={(0.5,-0.25)}, anchor=north, legend columns=4},
            ymajorgrids=true,
            legend cell align={left},
            ]
            \addplot[color=blue,mark=none,line width=0.7pt] 
            table[x=worker_count, y expr=\thisrow{txn}/10, col sep=comma] {data/var_0.csv};
            \addlegendentry{Bitmap}
                
            \addplot[color=red,mark=none,line width=0.7pt]
            table[x=worker_count, y expr=\thisrow{txn}/10, col sep=comma] {data/var_1.csv};
            \addlegendentry{Our}
                
            \addplot[color=black,mark=none,line width=0.7pt] 
            table[x=worker_count, y expr=\thisrow{txn}/10, col sep=comma] {data/var_2.csv};
            \addlegendentry{Scalable RL}
            
            \addplot[color=orange,mark=none,line width=0.7pt] 
            table[x=worker_count, y expr=\thisrow{txn}/10, col sep=comma] {data/var_3.csv};
            \addlegendentry{Song RL}
        \end{axis}
    \end{tikzpicture}
    \caption{Leanstore YCSB: Transactional Throughput [Txn/s].}
    \label{fig:txn_comparison}
\end{figure}

We evaluated the throughput of four competitors as the number of worker threads increased. 
The result is depicted in Figure \ref{fig:txn_comparison}. 
As anticipated, the \texttt{Bitmap} implementation consistently outperformed the other three competitors. 
This superiority can be attributed mainly to its optimized use of the aliasing arena, making it the most efficient workload handling. 
Our implementation (\texttt{Our}) demonstrated competitive performance, closely trailing \texttt{Bitmap} in terms of transactions per second. 
Both \texttt{Bitmap} and \texttt{Our} showed effective scalability with an increasing number of worker threads, though \texttt{Bitmap} maintained a consistent, albeit slight, performance advantage.

Conversely, \texttt{Song RL} initially exhibited substantial throughput but encountered a sharp decline beyond 24 worker threads. 
This decline underscores the limitations of its coarse-grained range lock mechanism, as discussed in Subsection \ref{subsec:listbase}. 
The single spinlock in \texttt{Song RL} becomes a significant bottleneck in high-contention scenarios, leading to marked performance degradation. 
On the other hand, the \texttt{Scalable RL} showed steady, linear throughput growth. 
However, its overall performance remained considerably lower than the other competitors, highlighting its limitations.

An additional key observation is the difficulty faced by the \texttt{Bitmap}, \texttt{Our}, and \texttt{Song RL} competitors in scaling effectively beyond 16 worker threads. 
This limitation is due mainly to the BLOB size in our workload. With a BLOB size of 1MB and 16 worker threads, the combined size of the client-side buffer and the internal DBMS memory block for the BLOB exceeds the L3 cache capacity (32MB in our machine), resulting in significant contention at the L3 cache. 
Furthermore, LeanStore's use of \texttt{memcpy} for read operations exacerbates this issue. \texttt{memcpy} consumes 2MB of memory read and write for every 1MB BLOB. 
An average throughput of approximately 60,000 operations per second equals over 110 GB of memory consumed by \texttt{memcpy}, which saturates the memory bandwidth and hinders the application's ability to scale.

\subsubsection*{Metric}


We also analyzed other performance of four methods in terms of CPU cycles, instructions, and L1 cache misses, as the number of workers increases. The result is depicted in Figure \ref{fig:txn_comparison}. 

In the first graph, which measures cycles, the \texttt{Scalable RL} has the highest amount of cycles as the worker count rises. 
This is predictable as we have observed that \texttt{Scalable RL} performs poorly in the benchmark above. 
In contrast, \texttt{Bitmap}, \texttt{Song RL}, and \texttt{Our} methods maintain much lower and more stable cycle counts, with the \texttt{Our} method closely matching the \texttt{Bitmap} method in performance. 

The second graph shows the number of instructions executed. 
The data indicates that, while the initial instruction count for \texttt{Scalable RL} is relatively high, it subsequently declines and stabilizes. 
The number of instructions of \texttt{Song RL} method exhibited a significant increase after reaching 25 threads, indicating the presence of a point of contention.
Otherwise, \texttt{Our} method exhibits a slightly higher instruction count compared to \texttt{Bitmap}, but the difference remains small. 

The third graph tracks L1 cache misses. 
It shows that \texttt{Scalable RL} suffers from the highest number of L1 misses, but again it subsequently declines and stabilizes. 
In contrast, \texttt{Bitmap}, \texttt{Song RL}, and \texttt{Our} methods keep their L1-miss counts low and stable across all workers. 

Overall, the \texttt{Our} method achieves efficient resource usage, closely matching \texttt{Bitmap} in cycles and L1 misses, while showing a small increase in instructions. This suggests that the \texttt{Our} method is a scalable and efficient solution that outperforms \texttt{Scalable RL} and performs nearly as well as \texttt{Bitmap} across all metrics.

\begin{figure}[h!]
    \centering

    % First graph: cycle/s
    \subfloat[Cycles on worker basis]{%
        \begin{tikzpicture}
            \begin{axis}[
                width=0.8\textwidth,
                height=0.35\textwidth,
                ylabel={Cycles (M)},
                xmin=0,
                ymin=0,
                ymax=9000000,
                xtick style={thick, black},
                ytick style={thick, black},
                ytick={0, 2000000, 4000000, 6000000, 8000000},
                yticklabels={$0$, $2M$, $4M$, $6M$, $8M$},
                tick align=center,
                legend style={at={(1,1)}, anchor=north east, legend columns=2, font=\tiny},
                scaled y ticks=false,
                ymajorgrids=true,
                grid=major,
                grid style=dashed,
                legend cell align={left},
            ]
    
            \addplot[color=blue,mark=none,line width=1pt] 
                table[x=worker_count, y=cycle, col sep=comma] {data/var_0.csv};
            \addlegendentry{Bitmap}
    
            \addplot[color=red,mark=none,line width=1pt] 
                table[x=worker_count, y=cycle, col sep=comma] {data/var_1.csv};
            \addlegendentry{Our}
    
            \addplot[color=black,mark=none,line width=1pt] 
                table[x=worker_count, y=cycle, col sep=comma] {data/var_2.csv};
            \addlegendentry{Scalable RL}
    
            \addplot[color=orange,mark=none,line width=1pt] 
                table[x=worker_count, y=cycle, col sep=comma] {data/var_3.csv};
            \addlegendentry{Song RL}
    
            \end{axis}
        \end{tikzpicture}
    }

    % Second graph: instr
    \subfloat[Instructions on worker basis]{%
        \begin{tikzpicture}
            \begin{axis}[
            width=0.8\textwidth,
            height=0.35\textwidth,
            ylabel={Instrs (M)},
            xmin=0,
            ymin=0,
            ymax=500000,
            xtick style={thick, black},
            ytick style={thick, black},
            ytick={0, 200000, 400000},
            yticklabels={$0$, $0.2M$, $0.4M$},
            tick align=center,
            legend style={at={(1,1)}, anchor=north east, legend columns=2, font=\tiny},
            scaled y ticks=false,
            ymajorgrids=true,
            grid=major,
            grid style=dashed,
            legend cell align={left},
            ]
    
            \addplot[color=blue,mark=none,line width=1pt] 
                table[x=worker_count, y=instr, col sep=comma] {data/var_0.csv};
            \addlegendentry{Bitmap}
    
            \addplot[color=red,mark=none,line width=1pt] 
                table[x=worker_count, y=instr, col sep=comma] {data/var_1.csv};
            \addlegendentry{Our}
    
            \addplot[color=black,mark=none,line width=1pt] 
                table[x=worker_count, y=instr, col sep=comma] {data/var_2.csv};
            \addlegendentry{Scalable RL}
    
            \addplot[color=orange,mark=none,line width=1pt] 
                table[x=worker_count, y=instr, col sep=comma] {data/var_3.csv};
            \addlegendentry{Song RL}
    
            \end{axis}
        \end{tikzpicture}%
    }

    % Third graph: L1-miss
    \subfloat[L1-misses on worker basis]{%
        \begin{tikzpicture}
            \begin{axis}[
            width=0.8\textwidth,
            height=0.35\textwidth,
            ylabel={L1-misses},
            xmin=0,
            ymin=0,
            ymax=90000,
            xtick style={thick, black},
            ytick style={thick, black},
            tick align=center,
            legend style={at={(1,1)}, anchor=north east, legend columns=2, font=\tiny},
            scaled y ticks=false,
            ymajorgrids=true,
            grid=major,
            grid style=dashed,
            legend cell align={left},
            ]
    
            \addplot[color=blue,mark=none,line width=1pt] 
                table[x=worker_count, y=L1-miss, col sep=comma] {data/var_0.csv};
            \addlegendentry{Bitmap}
    
            \addplot[color=red,mark=none,line width=1pt] 
                table[x=worker_count, y=L1-miss, col sep=comma] {data/var_1.csv};
            \addlegendentry{Our}
    
            \addplot[color=black,mark=none,line width=1pt] 
                table[x=worker_count, y=L1-miss, col sep=comma] {data/var_2.csv};
            \addlegendentry{Scalable RL}
    
            \addplot[color=orange,mark=none,line width=1pt] 
                table[x=worker_count, y=L1-miss, col sep=comma] {data/var_3.csv};
            \addlegendentry{Song RL}
    
            \end{axis}
        \end{tikzpicture}
    }

    \caption{Cycles, instructions, and L1-misses on worker basis}
    \label{fig:comparison_metrics}
\end{figure}


