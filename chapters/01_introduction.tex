\chapter{Introduction}\label{chapter:introduction}

In modern computing environments, multiple threads often need to concurrently access a shared resource, such as a database table, file region, or memory segment.
Systems often rely on coarser synchronization methods, like using a single lock to manage the access between threads. 
This leads to significant inefficiencies and performance bottlenecks at high concurrency levels. 
Range lock~\parencite{gao2023citron, kogan2020scalable, song2013parallelizing} provides a more refined approach to this challenge by partitioning a shared resource into multiple arbitrary-sized segments so that different processes can exclusively acquire and access each of these segments concurrently. 
This strategy effectively addresses the drawbacks and bottlenecks associated with single-lock methods, provides more granular control, and improves parallelism.

\textbf{Range locking is needed across various systems.}
Range locking is an understudied topic, yet it is important in various systems, including DBMS, file systems, and operating systems. 
In DBMS, range locks ensure data consistency and prevent anomalies such as phantoms, especially at the serializable isolation level. 
They secure not only individual records, but also the gaps between them, preventing other transactions from inserting or modifying records within the range until the transaction is complete. 
This is particularly challenging in systems where transaction control (TC) and data control (DC) are separated. 
TC must lock the range before safely interacting with DC, despite not knowing the specific keys involved. 
Similarly, in high-performance file systems, range locking allows multiple processes to access different file segments simultaneously, reducing contention and improving performance, especially in large, distributed environments. 
For operating systems, particularly within the Linux kernel, range locking is increasingly vital for alleviating contention issues associated with \texttt{mmap\_sem}, a semaphore that manages access to virtual memory areas (VMAs). 
As applications with large, dynamically allocated memory grow, contention for this semaphore can significantly degrade performance, making range locking a critical tool for maintaining efficiency and scalability in these diverse computing environments.

\textbf{Existing range lock is not efficient.}
Previous implementations of range-locking mechanisms often need to improve their performance. 
These implementations often suffer from contention points due to the reliance on a single lock~\parencite{linuxRangeLockImpl2013, song2013parallelizing}, as spinlock effectively serializes all incoming lock and unlock requests. 
Additionally, some methods may be complex and tightly coupled with lock-based concurrency control protocols, which are not applicable for general DBMS operations~\parencite{graefe2007hierarchical, andy2022database}. 
These limitations highlight the necessity for more refined and scalable solutions to better accommodate the demands of modern, large-scale systems. This drives us to develop an enhanced range lock.

\textbf{Contribution.} In the scope of this thesis, we introduce a new lock-free concurrent range lock. 
Our method addresses the inefficiencies of previous range locks and ensures high performance in highly concurrent environments. 
The result shows that our method is at least three times faster than existing solutions. 
This thesis provides an in-depth exploration of the development and evaluation of the proposed range-locking mechanism, offering a thorough understanding of its performance under heavy concurrent access. 
Furthermore, we compare the proposed solution with state-of-the-art methods, clearly assessing its effectiveness.