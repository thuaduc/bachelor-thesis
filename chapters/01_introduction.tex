\chapter{Introduction}\label{chapter:introduction}

In modern computing environments, concurrent threads must often synchronize access to overlapping shared resources, such as database tables, file regions, or memory segments. 
Systems often rely on coarser synchronization methods, like using a single lock to manage the access among threads. 
This leads to significant inefficiencies and performance bottlenecks under high concurrency. 
Range lock~\parencite{gao2023citron, kogan2020scalable, song2013parallelizing} provides a more refined approach to this challenge by partitioning a shared resource into multiple arbitrary-sized segments, so that different processes can exclusively acquire and access each of these segments concurrently. 
This strategy effectively addresses the drawbacks and bottlenecks associated with single-lock methods, allows for more granular control and improves parallelism.

\textbf{Range lock is needed across various systems.}
Range lock is an under-studied topic, while it is important across various systems, including DBMS, file systems, and operating systems. 
In DBMS, range lock ensures data consistency and prevents anomalies like "phantoms," especially under the serializable isolation level. 
They secure not only individual records but also the gaps between them, preventing other transactions from inserting or modifying records within the range until the transaction is complete. 
This is particularly challenging in systems where transaction control (TC) and data control (DC) are separated. 
TC must lock the range before safely interacting with DC, despite not knowing the specific keys involved. 
Similarly, in high-performance file systems, range lock enables multiple processes to access different file segments simultaneously, reducing contention and enhancing performance, especially in large-scale, distributed environments. 
For operating systems, particularly within the Linux kernel, range lock is increasingly vital for alleviating contention issues associated with \texttt{mmap\_sem}, a semaphore that manages access to virtual memory areas (VMAs). 
As applications with large, dynamically allocated memory grow, contention on this semaphore can significantly hinder performance, making range lock a critical tool for maintaining efficiency and scalability across these diverse computing environments.

\textbf{Existing range lock is not efficient.}
Previous implementations of range-locking mechanisms often need to improve their performance. 
These implementations often suffer from contention points due to the reliance on a single lock~\parencite{linuxRangeLockImpl2013, song2013parallelizing}, as spinlock effectively serializes all incoming lock and unlock requests. 
Additionally, some methods may be complex and tightly coupled with lock-based concurrency control protocols, which are not applicable for general DBMS operations~\parencite{graefe2007hierarchical, andy2022database}. 
These limitations highlight the necessity for more refined and scalable solutions to better accommodate the demands of modern, large-scale systems. This drives us to develop an enhanced range lock.

\textbf{Contribution.} In the scope of this thesis, we introduce a new lock-free concurrent range lock. 
Our method addresses the inefficiencies of previous range locks and ensures high performance in highly concurrent environments. 
Result shows that our method is at least three times faster than existing solutions. 
This thesis provides an in-depth exploration of the development and evaluation of the proposed range-locking mechanism, offering a thorough understanding of its performance under heavy concurrent access. 
Furthermore, we compare the proposed solution with state-of-the-art methods, providing a clear assessment of its effectiveness.