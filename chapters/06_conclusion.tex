\chapter{Conclusion}\label{chapter}

This thesis introduced a new lock-free concurrent range lock aimed at overcoming the limitations of existing range-locking methods. Traditional techniques, like coarse-grained locks and tree or list-based locks, often struggle in high-performance computing because of contention and poor scalability under heavy loads. We proposed a new solution based on a probabilistic skip list to tackle these issues. By using atomic operations like \texttt{compareAndSwap} to manage node references, we avoided the need for traditional locks. This design reduces bottlenecks and improves performance, making it a better fit for large-scale distributed systems.

Our evaluation, which included detailed tests and integration into the Leanstore storage engine, showed that our approach outperforms existing range-locking methods. We saw significant improvements in throughput and reduced contention across different workloads and thread counts, confirming that our mechanism is effective in real-world high-concurrency scenarios.

\subsection*{Future work}

Although we made significant progress, there are still areas that could be improved. One challenge we identified is that while our implementation works well, it doesn't scale as effectively when handling workloads beyond L3 cache sizes. This suggests a need to optimize our design for better cache efficiency, which would improve scalability in high-performance environments.

Another important area for future work is improving how we manage memory deallocation. The current design lacks an efficient memory cleanup strategy, which could lead to memory leaks or inefficient use of memory over time. Solving this issue will be key to enhancing the overall reliability and performance of our range-locking mechanism.

We also plan to take a closer look at the memory overhead created by our implementation. Using extra layers of linked lists and abstractions like \texttt{AtomicMarkableReference} adds some memory overhead. By analyzing this aspect and comparing it to other methods, we can better understand the trade-offs between memory usage and performance, which will help us refine our design.

Lastly, we want to explore how our concurrent range lock can be applied to other data structures or used in different contexts. For example, looking at the techniques used in the lock tree implementation in PerconaFT~\parencite{perconaft} could reveal new ways to improve the flexibility and usability of our approach. Investigating these areas could lead to further improvements and expand the potential applications of our range lock in high-concurrency environments.