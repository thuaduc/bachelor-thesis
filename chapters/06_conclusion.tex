\chapter{Conclusion}\label{chapter}

This thesis presented a new lock-free concurrent range lock to address the bottlenecks and inefficiencies in existing range-locking methods. Traditional techniques, such as coarse-grained locking and tree or list-based locks, often struggle in high-performance computing environments due to contention and poor scalability under heavy concurrency. We introduced a new approach based on a probabilistic skip list to tackle these challenges. We utilized atomic operations like \texttt{compareAndSet} to manage node references without relying on traditional locking mechanisms. This design significantly reduces bottlenecks and enhances concurrency performance, making it more suitable for large-scale distributed systems.

Our extensive evaluation, including microbenchmarks and integration into the Leanstore storage engine, demonstrated the superiority of our approach over existing range-locking methods. The results highlighted notable improvements in throughput and reduced contention across various workloads and thread counts, affirming the effectiveness of our mechanism in real-world, high-concurrency scenarios.

Despite these advancements, there are areas that warrant further exploration and optimization. One of the key challenges identified during our benchmarking is that our implementation, while effective, needs to scale better when dealing with workloads beyond L3 cache lines. This limitation suggests a need for further enhancement of our approach, particularly in terms of cache efficiency, to ensure better scalability in high-performance environments.

Another critical area for future work is the development of more efficient memory deallocation strategies. The current design lacks a robust mechanism for managing memory deallocation, which could lead to potential memory leaks or inefficient memory usage over time. Addressing this issue is crucial to improving the overall efficiency and reliability of our range-locking mechanism.

Additionally, we plan to conduct a detailed analysis of the memory overhead associated with our implementation. The use of additional layers of linked lists and abstractions like \texttt{AtomicMarkableReference} introduces a certain level of memory overhead. By thoroughly analyzing this aspect and comparing it with other competitors, we aim to gain a better understanding of the trade-offs between memory usage and performance, which will help us refine our approach further.

Furthermore, we want to explore how our concurrent range lock can be integrated with other data structures or applied in different contexts. For example, investigating the potential benefits of incorporating techniques used in the lock tree implementation in PerconaFT~\parencite{perconaft} could lead to new opportunities for enhancing the flexibility and applicability of our approach. Exploring these avenues could open up new possibilities for improving our design and expanding its utility across various high-concurrency environments.